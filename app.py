import streamlit as st
import pandas as pd
import plotly.express as px
import io
from datetime import datetime

st.set_page_config(page_title="Analyse sous-groupe soins", layout="wide")

st.title("üìä Analyse du sous-groupe ¬´ soins ¬ª ‚Äì avec logique d‚Äôentr√©es, sorties et arr√™ts")

st.markdown(
    """
Cette application permet d'analyser les **√©volutions du co√ªt global** par salari√©
pour un sous-groupe (par exemple *soins*), √† partir d'un fichier Excel au format :

- `Salarie`
- `Sous_groupe`
- Colonnes mensuelles : `janv-24`, `f√©vr-24`, ..., `oct-25`

Elle ajoute une **logique m√©tier** :

- d√©tection des **entr√©es / sorties en cours d‚Äôann√©e**,
- rep√©rage des mois d‚Äô**activit√© tr√®s faible** (souvent des arr√™ts, cong√©s longs, temps partiel tr√®s r√©duit),
- calcul du **plus long bloc cons√©cutif** de ces mois ‚Äúfaibles‚Äù.

Toutes les visualisations sont faites avec **Plotly**.
"""
)

# --------------------------------------------------------
# 1. UPLOAD FICHIER
# --------------------------------------------------------
uploaded_file = st.file_uploader("üìÇ Importer le fichier Excel (tableau r√©cap)", type=["xlsx"])

if uploaded_file is None:
    st.info("D√©pose un fichier Excel pour commencer.")
    st.stop()

# Lecture du fichier (1√®re feuille)
df_raw = pd.read_excel(uploaded_file)

st.subheader("üëÅ‚Äçüó® Aper√ßu des donn√©es import√©es")
st.dataframe(df_raw.head(), use_container_width=True)

# V√©rif colonnes
required_cols = {"Salarie", "Sous_groupe"}
if not required_cols.issubset(df_raw.columns):
    st.error(f"Le fichier doit contenir au minimum les colonnes : {required_cols}")
    st.stop()

# --------------------------------------------------------
# 2. PR√âPARATION DES DONN√âES
# --------------------------------------------------------

# Colonnes de p√©riodes = toutes sauf identifiants
id_cols = ["Salarie", "Sous_groupe"]
period_cols = [c for c in df_raw.columns if c not in id_cols]

if len(period_cols) == 0:
    st.error("Aucune colonne de mois d√©tect√©e (en dehors de Salarie / Sous_groupe).")
    st.stop()

# On cr√©e une correspondance "nom de colonne" -> vraie date (en partant de janv-2024)
# On suppose que les colonnes sont d√©j√† dans l'ordre chronologique.
dates = pd.date_range("2024-01-01", periods=len(period_cols), freq="MS")
col_to_date = dict(zip(period_cols, dates))

# Passage au format long
df_long = df_raw.melt(
    id_vars=id_cols,
    value_vars=period_cols,
    var_name="Periode_label",
    value_name="Cout_global",
)

# Ajout de la date r√©elle
df_long["Date"] = df_long["Periode_label"].map(col_to_date)
df_long = df_long.dropna(subset=["Date"])  # au cas o√π
df_long["Year"] = df_long["Date"].dt.year

# On garde uniquement les lignes avec un co√ªt renseign√©
df_long = df_long.dropna(subset=["Cout_global"])

# --------------------------------------------------------
# 2bis. CHOIX DU SOUS-GROUPE
# --------------------------------------------------------
st.subheader("üéØ Choix du sous-groupe √† analyser")
group_options = sorted(df_long["Sous_groupe"].dropna().unique().tolist())
default_idx = group_options.index("soins") if "soins" in group_options else 0
selected_group = st.selectbox("Sous-groupe :", group_options, index=default_idx)

df_group = df_long[df_long["Sous_groupe"] == selected_group].copy()

if df_group.empty:
    st.warning(f"Aucune donn√©e pour le sous-groupe ¬´ {selected_group} ¬ª.")
    st.stop()

# --------------------------------------------------------
# 2ter. LOGIQUE ARR√äTS / ENTR√âES / SORTIES
# --------------------------------------------------------

st.subheader("üß© Param√®tres de d√©tection des arr√™ts")

seuil_absence = st.slider(
    "Seuil de co√ªt mensuel en-dessous duquel on consid√®re un mois comme ¬´ activit√© tr√®s r√©duite / arr√™t ¬ª :",
    min_value=0,
    max_value=3000,
    value=1500,
    step=100,
    help="En-dessous de ce montant, on consid√®re que le salari√© n'est que tr√®s peu pr√©sent (arr√™t, cong√© long, temps partiel tr√®s r√©duit...).",
)

# Index temporel global
dates_sorted = sorted(df_group["Date"].unique())
date_to_idx = {d: i for i, d in enumerate(dates_sorted)}
df_group["idx"] = df_group["Date"].map(date_to_idx)

global_first_idx = 0
global_last_idx = len(dates_sorted) - 1

def longest_true_streak(bool_list):
    """Retourne la longueur max de 'True' cons√©cutifs dans une liste bool√©enne."""
    max_streak = 0
    streak = 0
    for val in bool_list:
        if val:
            streak += 1
            max_streak = max(max_streak, streak)
        else:
            streak = 0
    return max_streak

def parcours_logic(sub):
    """Calcule la logique entr√©e/sortie/arr√™ts pour un salari√©."""
    sub = sub.sort_values("idx")
    first_idx = int(sub["idx"].min())
    last_idx = int(sub["idx"].max())

    entree = first_idx > global_first_idx
    sortie = last_idx < global_last_idx

    faible = (sub["Cout_global"] <= seuil_absence) | sub["Cout_global"].isna()
    nb_faibles = int(faible.sum())
    longest = int(longest_true_streak(list(faible)))

    return pd.Series({
        "entree_en_cours": entree,
        "sortie_en_cours": sortie,
        "nb_mois_faibles": nb_faibles,
        "plus_long_arret": longest,
    })

parcours = (
    df_group.groupby("Salarie")
    .apply(parcours_logic)
    .reset_index()
)

# --------------------------------------------------------
# 3. INDICATEURS PAR SALARI√â
# --------------------------------------------------------

# Moyenne annuelle par salari√©
annual_mean = (
    df_group
    .groupby(["Salarie", "Sous_groupe", "Year"], as_index=False)["Cout_global"]
    .mean()
)

# Pivot pour avoir 2024 / 2025 c√¥te √† c√¥te
resume = annual_mean.pivot_table(
    index=["Salarie", "Sous_groupe"],
    columns="Year",
    values="Cout_global"
).reset_index()

# Renommage plus lisible
col_2024 = 2024 if 2024 in resume.columns else None
col_2025 = 2025 if 2025 in resume.columns else None

if col_2024 is not None:
    resume["moy_2024"] = resume[col_2024]
else:
    resume["moy_2024"] = pd.NA

if col_2025 is not None:
    resume["moy_2025"] = resume[col_2025]
else:
    resume["moy_2025"] = pd.NA

# Variation absolue / relative
resume["var_abs"] = resume["moy_2025"] - resume["moy_2024"]
resume["var_rel_%"] = resume["var_abs"] / resume["moy_2024"] * 100

# Volatilit√© (√©cart-type)
volatility = (
    df_group
    .groupby("Salarie")["Cout_global"]
    .std()
    .rename("ecart_type")
    .reset_index()
)

resume = resume.merge(volatility, on="Salarie", how="left")

# Anomalies (valeurs tr√®s faibles ou n√©gatives)
df_group["Anomalie"] = (df_group["Cout_global"] <= 0) | (df_group["Cout_global"] < 500)
anom_summary = (
    df_group.groupby("Salarie")["Anomalie"]
    .sum()
    .rename("nb_anomalies")
    .reset_index()
)

resume = resume.merge(anom_summary, on="Salarie", how="left")
resume["nb_anomalies"] = resume["nb_anomalies"].fillna(0).astype(int)

# Ajout de la logique de parcours (entr√©es, sorties, arr√™ts)
resume = resume.merge(parcours, on="Salarie", how="left")

# Tri par variation d√©croissante
resume_sorted = resume.sort_values("var_abs", ascending=False)

# --------------------------------------------------------
# 4. R√âSUM√â GLOBAL
# --------------------------------------------------------

st.subheader("üìå R√©sum√© global du sous-groupe")

sum_2024 = df_group[df_group["Year"] == 2024]["Cout_global"].sum()
sum_2025 = df_group[df_group["Year"] == 2025]["Cout_global"].sum()
delta_total = sum_2025 - sum_2024

col1, col2, col3 = st.columns(3)
col1.metric("Total 2024", f"{sum_2024:,.0f} ‚Ç¨".replace(",", " "))
col2.metric("Total 2025", f"{sum_2025:,.0f} ‚Ç¨".replace(",", " "),
            delta=f"{delta_total:,.0f} ‚Ç¨".replace(",", " "))
if sum_2024 != 0:
    col3.metric("√âvolution globale", f"{(delta_total / sum_2024 * 100):.1f} %")
else:
    col3.metric("√âvolution globale", "n/a")

nb_entrees = int(resume["entree_en_cours"].sum())
nb_sorties = int(resume["sortie_en_cours"].sum())
nb_long_arrets = int((resume["plus_long_arret"] >= 2).sum())

st.markdown(
    f"""
- **{nb_entrees} salari√©(s)** semblent **entrer en cours de p√©riode** (pas de co√ªt sur les premiers mois).
- **{nb_sorties} salari√©(s)** semblent **sortir en cours de p√©riode**.
- **{nb_long_arrets} salari√©(s)** pr√©sentent au moins **2 mois cons√©cutifs** en-dessous de {seuil_absence} ‚Ç¨,  
  ce qui ressemble √† des **arr√™ts / longues absences**.
"""
)

# Graphique global : √©volution mensuelle totale du sous-groupe
st.markdown("### üìâ √âvolution mensuelle globale du sous-groupe")
agg_month = (
    df_group.groupby("Date", as_index=False)["Cout_global"]
    .sum()
    .sort_values("Date")
)

fig_tot = px.line(
    agg_month,
    x="Date",
    y="Cout_global",
    markers=True,
    title=f"Co√ªt global mensuel du sous-groupe ¬´ {selected_group} ¬ª",
)
fig_tot.update_layout(
    xaxis_title="Mois",
    yaxis_title="Co√ªt global (‚Ç¨)",
    xaxis_tickformat="%m/%Y",
)
st.plotly_chart(fig_tot, use_container_width=True)

# --------------------------------------------------------
# 5. TOP HAUSSES / BAISSES
# --------------------------------------------------------

st.subheader("üèÜ Salari√©s qui expliquent les principales √©volutions")

top_n = st.slider("Nombre de salari√©s √† afficher dans les classements :", 5, 20, 10)

# Top hausses
top_up = resume_sorted.head(top_n)
# Top baisses
top_down = resume_sorted.sort_values("var_abs", ascending=True).head(top_n)

col_up, col_down = st.columns(2)

with col_up:
    st.markdown("#### üìà Plus fortes **hausses** (moyenne 2025 vs 2024)")
    fig_up = px.bar(
        top_up,
        x="Salarie",
        y="var_abs",
        hover_data=[
            "moy_2024",
            "moy_2025",
            "var_rel_%",
            "ecart_type",
            "nb_anomalies",
            "entree_en_cours",
            "sortie_en_cours",
            "plus_long_arret",
        ],
        title="Top hausses de co√ªt moyen annuel",
    )
    fig_up.update_layout(xaxis_title="", yaxis_title="Variation absolue (‚Ç¨)")
    fig_up.update_xaxes(tickangle=45)
    st.plotly_chart(fig_up, use_container_width=True)

with col_down:
    st.markdown("#### üìâ Plus fortes **baisses**")
    fig_down = px.bar(
        top_down,
        x="Salarie",
        y="var_abs",
        hover_data=[
            "moy_2024",
            "moy_2025",
            "var_rel_%",
            "ecart_type",
            "nb_anomalies",
            "entree_en_cours",
            "sortie_en_cours",
            "plus_long_arret",
        ],
        title="Top baisses de co√ªt moyen annuel",
    )
    fig_down.update_layout(xaxis_title="", yaxis_title="Variation absolue (‚Ç¨)")
    fig_down.update_xaxes(tickangle=45)
    st.plotly_chart(fig_down, use_container_width=True)

# --------------------------------------------------------
# 6. NIVEAU vs VOLATILIT√â (avec logique)
# --------------------------------------------------------

st.subheader("üå™ Stabilit√© vs niveau de co√ªt (en tenant compte des arr√™ts)")

df_scatter = resume.dropna(subset=["moy_2024", "ecart_type", "var_abs"]).copy()

if df_scatter.empty:
    st.info("Pas assez de donn√©es compl√®tes pour afficher le graphique de stabilit√©.")
else:
    df_scatter["size_var"] = df_scatter["var_abs"].abs()

    fig_scatter = px.scatter(
        df_scatter,
        x="moy_2024",
        y="ecart_type",
        size="size_var",
        color="var_abs",
        hover_data=[
            "Salarie",
            "moy_2025",
            "var_rel_%",
            "nb_anomalies",
            "entree_en_cours",
            "sortie_en_cours",
            "plus_long_arret",
            "nb_mois_faibles",
        ],
        title="Niveau moyen 2024 vs volatilit√© (variation en taille/couleur, arr√™ts en info-bulle)",
    )
    fig_scatter.update_layout(
        xaxis_title="Co√ªt moyen 2024 (‚Ç¨)",
        yaxis_title="√âcart-type du co√ªt mensuel (‚Ç¨)",
    )
    st.plotly_chart(fig_scatter, use_container_width=True)

    st.markdown(
        f"""
**Lecture :**

- Les points en haut sont les salari√©s **instables** (forte variabilit√©).
- Les bulles grandes repr√©sentent les salari√©s avec une **grosse variation moyenne** entre 2024 et 2025.
- Les infos-bulles indiquent s'il s'agit plut√¥t d'un **effet structurel** (arriv√©e/d√©part),
  de **longs arr√™ts** (*plus_long_arret ‚â• 2 mois sous {seuil_absence} ‚Ç¨*),
  ou d'une vraie **augmentation de rythme / de quotit√©**.
"""
    )

# --------------------------------------------------------
# 7. ANOMALIES
# --------------------------------------------------------

st.subheader("‚ö†Ô∏è Anomalies possibles (tr√®s faible ou n√©gatif)")

df_anom = df_group[df_group["Anomalie"]].copy()
if df_anom.empty:
    st.info("Aucune anomalie nette d√©tect√©e (co√ªt < 500 ‚Ç¨ ou ‚â§ 0).")
else:
    st.markdown(
        """
Les lignes ci-dessous correspondent √† des **co√ªts mensuels tr√®s faibles ou n√©gatifs**  
(qui peuvent √™tre soit des **erreurs de donn√©es**, soit des cas particuliers √† v√©rifier : r√©gularisations, fins de contrat, etc.).
"""
    )
    st.dataframe(
        df_anom.sort_values(["Salarie", "Date"])[
            ["Salarie", "Date", "Cout_global", "Periode_label"]
        ],
        use_container_width=True,
    )

# --------------------------------------------------------
# 8. R√âCAPITULATIF & EXPORT
# --------------------------------------------------------

st.subheader("üìã Tableau r√©capitulatif par salari√©")

affiche_cols = [
    "Salarie",
    "Sous_groupe",
    "moy_2024",
    "moy_2025",
    "var_abs",
    "var_rel_%",
    "ecart_type",
    "nb_anomalies",
    "entree_en_cours",
    "sortie_en_cours",
    "nb_mois_faibles",
    "plus_long_arret",
]

st.dataframe(
    resume_sorted[affiche_cols],
    use_container_width=True,
)

# Petite synth√®se automatique plus "logique"
st.markdown("### üß† Synth√®se automatique (version m√©tier)")

top_contrib = resume_sorted.head(5)
if delta_total != 0:
    part_top = (top_contrib["var_abs"].sum() / delta_total * 100)
else:
    part_top = 0

sal_instable = resume_sorted.sort_values("ecart_type", ascending=False).iloc[0]

st.markdown(
    f"""
- Les **5 plus fortes hausses** expliquent environ **{part_top:.1f} %** de la variation totale du groupe.
- Parmi ces 5, **{int((top_contrib['entree_en_cours']).sum())}** sont des **entr√©es en cours de p√©riode**
  et **{int((top_contrib['plus_long_arret'] >= 2).sum())}** ont au moins **un arr√™t long**,  
  ce qui indique que la hausse est souvent li√©e √† un **changement de pr√©sence** plut√¥t qu'√† une pure hausse de co√ªt horaire.
- Le salari√© le plus instable est **{sal_instable['Salarie']}**  
  (√©cart-type ‚âà {sal_instable['ecart_type']:.0f} ‚Ç¨, plus long arr√™t : {int(sal_instable['plus_long_arret'])} mois).
"""
)

# Export Excel
buffer = io.BytesIO()
with pd.ExcelWriter(buffer, engine="xlsxwriter") as writer:
    resume_sorted.to_excel(writer, index=False, sheet_name="Resume_sous_groupe")
    df_group.to_excel(writer, index=False, sheet_name="Detail_long")

st.download_button(
    "üíæ T√©l√©charger le fichier d'analyse (Excel)",
    data=buffer.getvalue(),
    file_name=f"analyse_{selected_group}.xlsx",
    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
)
